It seems that currently there are two 
prominent approaches regarding music 
genre classification using deep learning. 
The first focuses on genre classification 
using CNN (convolutional neural networks).
CNN have been shown to be effective in speech 
recognition and computer vision, as well as 
classification tasks such as music genre classification, 
and are known for their pattern detection capabilities.
The second approach uses RNN. Recurrent Neural Networks 
(RNN) have shown success in many sequential tasks 
including Machine Translation and Speech Recognition,
out-performing state-of-the-art systems which use 
hand-crafted features. We intend on combining the two approaches, 
in hope that they would contribute non-overlapping 
essential information about the data, 
that would enable better classification.
We also intend to examine the effect of attention on 
RNN based music classification models.